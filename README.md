# ğŸ’¡ RECOGNIZE-SPEAKERS-IN-TEXT ğŸ“„

**ëª¨ë¸ ì„¤ëª…**: ë„¤ì´ë²„ ì›¹ì†Œì„¤ í…ìŠ¤íŠ¸ë¥¼ ë“œë¼ë§ˆ ê°ë³¸ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. 

**MODEL DESCRIPTION**: A model that converts the text of Naver's web novel into a drama script.

---
1. **ì´ˆë¡**

  ìŒì„± ì¸ì‹ ë¶„ì•¼ì—ì„œì˜ ë°œí™”ì ì¸ì‹ ê¸°ìˆ ê³¼ ë‹¬ë¦¬, í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë‚´ ë°œí™”ì ì¸ì‹ ê¸°ìˆ ì€ ê·¸ í•„ìš”ì„±ì—ë„ ë¶ˆêµ¬í•˜ê³  ë°œì „ì´ ë”ë”¥ë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ë„ ì´ ë¶„ì•¼ì—ì„œëŠ” ê°•í•œ ì„±ëŠ¥ì„ ë³´ì´ì§€ ëª»í•©ë‹ˆë‹¤. ë³¸ ëª¨ë¸ì€ ì •í™•ë„ë¥¼ ìœ„í•œ ë£° ë² ì´ìŠ¤ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬ì™€ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ ì‚¬ìš©ìœ¼ë¡œ ì›¹ì†Œì„¤ì—ì„œ í™”ìë¥¼ ì¸ì‹í•©ë‹ˆë‹¤. ë°œí™”ê°€ ì´ë£¨ì–´ì§€ëŠ” ì‹œê°„ê³¼ ê³µê°„ì˜ ì¸ì‹ì„ í†µí•´ ì¥ë©´ì„ êµ¬ë¶„í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë“œë¼ë§ˆ ê°ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤. ì›¹ì†Œì„¤ ë¶„ì•¼ë¥¼ ì„ íƒí•œ ì´ìœ ëŠ” ìƒì—…ì„±ê³¼ ë¬¸ì„œì˜ íŠ¹ì§• ë•Œë¬¸ì…ë‹ˆë‹¤. ì›¹ì†Œì„¤ì€ ìµœê·¼ ìì²´ ì‹œì¥ê³¼ ë“œë¼ë§ˆ/ì˜í™” ë“± 2ì°¨ ê°€ê³µë¬¼ ì‹œì¥ì—ì„œ ë›°ì–´ë‚œ ë§¤ì¶œ ì‹¤ì ì„ ë³´ì…ë‹ˆë‹¤. ë˜, ëŒ€ë¶€ë¶„ íœ´ëŒ€ì „í™”ë¡œ ì½ëŠ”ë‹¤ëŠ” íŠ¹ì„± ë•Œë¬¸ì— ë°œí™”ì™€ ì¥ë©´ ì „í™˜ë§ˆë‹¤ì˜ ì¤„ë°”ê¿ˆì´ ëª…í™•í•©ë‹ˆë‹¤. ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. [ì„±ëŠ¥í‰ê°€ ê²°ê³¼ ì„œìˆ ]

1. **ABSTRACT**

   Unlike speaker recognition technology in the field of speech recognition, speaker recognition technology in Korean text is slow to develop despite its need. The Transformer models also don't have strong performance in this area. Our model recognizes speakers in web novels with rule-based pre-processing and post-processing for accuracy and the use of Transformer models. The scene is distinguished through the perception of the time and space in which the utterance takes place, and a drama script is generated based on this. We chose the web novel field because of its commerciality and document characteristics. Web novels have recently shown outstanding sales performance in their own markets and secondary production markets such as dramas and movies. In addition, because most of them are read on mobile phones, the line changes for each speech and scene change are clear. The performance evaluation results of the model are as follows. [Description of performance evaluation results]
   
---
2. **ë°°ê²½**
   
   ë°œí™”ì ì¸ì‹ì€ ìŒì„± ì¸ì‹ ë¶„ì•¼ì—ì„œ ì£¼ë¡œ ë°œì „ë˜ì–´ ì™”ìœ¼ë©°, ë¬¸ì„œ ì† ë°œí™”ì ì¸ì‹ ê¸°ìˆ ì€ ë‘ê°ì„ ë“œëŸ¬ë‚´ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì„œì—ì„œë„ ë°œí™”ì ì¸ì‹ì€ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¯¸ ê¸°ë¡ëœ ë¬¸ì„œì—ì„œ ë°œí™”ìë¥¼ ì¸ì‹í•˜ê³  ì°¾ëŠ” ì‘ì—…ì€ í˜„ì¬ ì‚¬ëŒì´ ë‹´ë‹¹í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ íšŒì˜, ìƒë‹´, ì†Œì„¤ ë“± ìŒì„±ì´ ì—†ëŠ” í…ìŠ¤íŠ¸ì—ì„œ ë°œí™”ìë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤ë©´ ìƒì‚°ì„±ì´ ë¹„ì•½ì ìœ¼ë¡œ ìƒìŠ¹í•  ê²ƒì…ë‹ˆë‹¤. ì´ëŸ¬í•œ í•„ìš”ì—ë„ ë¶ˆêµ¬í•˜ê³  í…ìŠ¤íŠ¸ ë‚´ ë°œí™”ì ì¸ì‹ ê¸°ìˆ ì´ ë°œì „í•˜ì§€ ëª»í•œ ê²ƒì€ êµ¬í˜„ì˜ ì–´ë ¤ì›€ ë•Œë¬¸ì…ë‹ˆë‹¤. íŠ¹íˆ ìš°ë¦¬ë§ì˜ ê²½ìš°, ì˜ì–´ì™€ ë‹¬ë¦¬ ì¸ì¹­ì˜ êµ¬ë¶„ì´ ì—†ìœ¼ë©° ì£¼ì–´ì˜ ìƒëµì´ ì¦ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë°œí™” ì¸ì‹ì„ ìœ„í•´ì„œëŠ” ì•ë’¤ ë¬¸ë§¥ì˜ ê³ ë ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.
   
   ëŒ€ë¶€ë¶„ì˜ ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì´ì „ê³¼ ì´í›„ë¡œ í¬ê²Œ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤. chatGPTëŠ” NLUë¥¼ ì‹¤í˜„í•œ ê²ƒì²˜ëŸ¼ ë³´ì´ë©°, hallucination ë“±ì˜ ë¬¸ì œì—ë„ ë¶ˆêµ¬í•˜ê³  ë§ì€ ì‚¬ëŒì˜ ì„±ì›ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë‚´ ë°œí™”ì ì¸ì‹ ì˜ì—­ë„ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì‚¬ìš©ìœ¼ë¡œ ê¸°ì¡´ë³´ë‹¤ ìš©ì´í•´ì§ˆ ê²ƒì´ë¼ ì˜ˆìƒí–ˆìœ¼ë‚˜, ì‹¤ì œëŠ” ì˜ˆìƒê³¼ ë‹¬ëìŠµë‹ˆë‹¤. #Markus Krug#ì— ë”°ë¥´ë©´, ë£° ê¸°ë°˜ ë°©ì‹ê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë°œí™”ì ì¸ì‹ ì •í™•ë„ë¥¼ ë¹„êµí–ˆì„ ë•Œ í›„ìê°€ ìœ ì˜í•˜ê²Œ ë†’ì§€ ì•ŠìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.



2. **BACKGROUND AND PROBLEMS**
     
   Speaker recognition has mainly developed in the field of speech recognition, and speaker recognition technology in documents has not been prominent. However, the document also requires speaker recognition. Recognizing and finding speakers in already recorded documents is currently handled by a person. Therefore, productivity will rise dramatically if we can distinguish speakers from non-voice texts such as meetings, counseling, and novels. Despite this need, speaker recognition technology in the text has not advanced because of the difficulty of implementation. In particular, in the case of Korean, unlike English, there is no distinction between grammatical person, and the subject is often omitted. Therefore, consideration of the context before and after is required for speech recognition.
   
---
 2. **ì„ í–‰ ì—°êµ¬**
    1. í•œêµ­ì–´
    2. ì˜ì–´
    3. ê·¸ ì™¸
   
  2. **Related Works**
---
 3. **ë¶„ì•¼ ì„ ì •**
    1. ì›¹ì†Œì„¤
    2. ë“œë¼ë§ˆ
   
---
 4. **ì‚¬ìš© ê¸°ìˆ **
    1. Named Entity Recognition (NER)
    2. Relation Extraction (RE)
    3. Pretrained Models
   
---
 5. **ë°ì´í„°**
    1. ë„¤ì´ë²„ ì›¹ì†Œì„¤ ë¬´ë£Œë³¸
    2. ë“œë¼ë§ˆ ê°ë³¸
---
 6. **ëª¨ë¸**

---
 7. **ì„±ëŠ¥**

---
 8. **ë°°í¬**
